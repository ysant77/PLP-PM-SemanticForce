Besides T5 model, GPT2-Summarizer, fine-tuning of GPT2-small, GPT2-medium and BART was also explored. 
However, the performance of these models did not match that of the T5 model, as indicated by the Rouge scores and qualitative assessment of the generated summaries. 
Specifically, while BART showed promising results, the outputs from the fine-tuned GPT2 models exhibited a lack of coherence, particularly towards the latter part of the generated text.
Files and Outputs are stored in this folder.
